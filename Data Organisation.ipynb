{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf3604da",
   "metadata": {},
   "source": [
    "This script handles the organization of the preprocessed MRI data into a structured folder hierarchy. Data are separated by modality and patient, with each patient folder containing the corresponding image slices and segmentation masks. It also filters out slices containing only background to reduce class imbalance, generating the final dataset structure used in subsequent experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "preprocessed_base = \"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/preprocessed_data/min_max_normalized_images\"\n",
    "dataset_ready_2D = \"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/dataset_ready_2D\"\n",
    "\n",
    "modalities = [\"T2SPIR\", \"T1DUAL_InPhase\", \"T1DUAL_OutPhase\"]\n",
    "\n",
    "# Create dataset_ready_2D folder structure\n",
    "for modality in modalities:\n",
    "    modality_dir = os.path.join(dataset_ready_2D, modality, \"images\")\n",
    "    os.makedirs(modality_dir, exist_ok=True)\n",
    "\n",
    "# List all patients (use one modality as reference)\n",
    "patients = sorted([\n",
    "    p for p in os.listdir(os.path.join(preprocessed_base, \"T2SPIR\"))\n",
    "    if os.path.isdir(os.path.join(preprocessed_base, \"T2SPIR\", p))\n",
    "])\n",
    "\n",
    "# Copy DICOM slices into a folder per patient\n",
    "for modality in modalities:\n",
    "    out_modality_dir = os.path.join(dataset_ready_2D, modality, \"images\")\n",
    "    \n",
    "    for patient in tqdm(patients, desc=f\"Copying DICOM slices for {modality}\"):\n",
    "        patient_mod_path = os.path.join(preprocessed_base, modality, patient)\n",
    "        if not os.path.isdir(patient_mod_path):\n",
    "            continue\n",
    "\n",
    "        dicom_files = sorted([f for f in os.listdir(patient_mod_path) if f.lower().endswith(\".dcm\")])\n",
    "        if not dicom_files:\n",
    "            continue\n",
    "\n",
    "        # Create a folder for this patient inside the modality folder\n",
    "        patient_out_dir = os.path.join(out_modality_dir, patient)\n",
    "        os.makedirs(patient_out_dir, exist_ok=True)\n",
    "\n",
    "        # Copy all slices into the patient's folder\n",
    "        for f in dicom_files:\n",
    "            src = os.path.join(patient_mod_path, f)\n",
    "            dst = os.path.join(patient_out_dir, f)\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "print(\"✅ Dataset ready 2D: each patient has its own folder per modality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfdb3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_patients = ['13', '19', '2', '20', '3', '38','8']\n",
    "resized_masks_path = r\"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/resized_data\"\n",
    "converted_masks_path = r\"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/converted_masks\"\n",
    "dataset_ready_2D = r\"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/dataset_ready_2D\"\n",
    "\n",
    "modalities = [\"T2SPIR\", \"T1DUAL_InPhase\", \"T1DUAL_OutPhase\"]\n",
    "\n",
    "# Process each modality separately\n",
    "for modality in modalities:\n",
    "    modality_dir = os.path.join(dataset_ready_2D, modality)\n",
    "    masks_dir = os.path.join(modality_dir, \"masks\")\n",
    "    os.makedirs(masks_dir, exist_ok=True)\n",
    "\n",
    "    # Determine base modality for masks (T1DUAL special case)\n",
    "    base_mod = \"T1DUAL\" if \"T1DUAL\" in modality else modality\n",
    "\n",
    "    # List patient folders in images_dir\n",
    "    images_dir = os.path.join(modality_dir, \"images\")\n",
    "    patients = sorted([p for p in os.listdir(images_dir)\n",
    "                       if os.path.isdir(os.path.join(images_dir, p))])\n",
    "\n",
    "    for patient in tqdm(patients, desc=f\"Organizing masks for {modality}\"):\n",
    "\n",
    "        # Determine mask folder\n",
    "        if patient in special_patients:\n",
    "            mask_path = os.path.join(resized_masks_path, patient, base_mod, \"Ground\")\n",
    "        else:\n",
    "            mask_path = os.path.join(converted_masks_path, patient, base_mod)\n",
    "\n",
    "        if not os.path.isdir(mask_path):\n",
    "            print(f\"Warning: mask folder not found: {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        mask_files = sorted([f for f in os.listdir(mask_path) if f.lower().endswith((\".png\", \".jpg\"))])\n",
    "        if not mask_files:\n",
    "            print(f\"No mask files for patient {patient} in {mask_path}\")\n",
    "            continue\n",
    "\n",
    "        # --- Create a folder for this patient ---\n",
    "        patient_mask_dir = os.path.join(masks_dir, patient)\n",
    "        os.makedirs(patient_mask_dir, exist_ok=True)\n",
    "\n",
    "        # Copy all masks into the patient folder\n",
    "        for f in mask_files:\n",
    "            src = os.path.join(mask_path, f)\n",
    "            \n",
    "            dst = os.path.join(patient_mask_dir, f)  # keep original filename\n",
    "            shutil.copy2(src, dst)\n",
    "\n",
    "print(\"✅ All masks are organized into patient folders per modality.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bcb2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def mask_has_foreground(mask_path):\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        return False\n",
    "    return np.any(mask > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0b6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_patients = ['13', '19', '2', '20', '3', '38', '8']\n",
    "\n",
    "resized_masks_path = r\"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/resized_data\"\n",
    "converted_masks_path = r\"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/converted_masks\"\n",
    "\n",
    "dataset_src = r\"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/dataset_ready_2D\"\n",
    "dataset_dst = r\"/content/drive/My Drive/CHAOS_Train_Sets/Train_Sets/dataset_ready_2D_filtered\"\n",
    "\n",
    "modalities = [\"T2SPIR\", \"T1DUAL_InPhase\", \"T1DUAL_OutPhase\"]\n",
    "\n",
    "for modality in modalities:\n",
    "    print(f\"\\nProcessing modality: {modality}\")\n",
    "\n",
    "    base_mod = \"T1DUAL\" if \"T1DUAL\" in modality else modality\n",
    "\n",
    "    src_img_root = os.path.join(dataset_src, modality, \"images\")\n",
    "    dst_img_root = os.path.join(dataset_dst, modality, \"images\")\n",
    "    dst_mask_root = os.path.join(dataset_dst, modality, \"masks\")\n",
    "\n",
    "    os.makedirs(dst_img_root, exist_ok=True)\n",
    "    os.makedirs(dst_mask_root, exist_ok=True)\n",
    "\n",
    "    patients = sorted([\n",
    "        p for p in os.listdir(src_img_root)\n",
    "        if os.path.isdir(os.path.join(src_img_root, p))\n",
    "    ])\n",
    "\n",
    "    for patient in tqdm(patients, desc=f\"Filtering {modality}\"):\n",
    "\n",
    "        # source folders\n",
    "        img_src_dir = os.path.join(src_img_root, patient)\n",
    "\n",
    "        if patient in special_patients:\n",
    "            mask_src_dir = os.path.join(resized_masks_path, patient, base_mod, \"Ground\")\n",
    "        else:\n",
    "            mask_src_dir = os.path.join(converted_masks_path, patient, base_mod)\n",
    "\n",
    "        if not os.path.isdir(mask_src_dir):\n",
    "            continue\n",
    "\n",
    "        img_files = sorted([f for f in os.listdir(img_src_dir) if f.endswith(\".dcm\")])\n",
    "        mask_files = sorted([f for f in os.listdir(mask_src_dir) if f.lower().endswith((\".png\", \".jpg\"))])\n",
    "\n",
    "        if not img_files or not mask_files:\n",
    "            continue\n",
    "\n",
    "        kept_pairs = []\n",
    "\n",
    "        # ✅ align by order (as you verified)\n",
    "        for img_f, mask_f in zip(img_files, mask_files):\n",
    "            mask_path = os.path.join(mask_src_dir, mask_f)\n",
    "\n",
    "            if mask_has_foreground(mask_path):\n",
    "                kept_pairs.append((img_f, mask_f))\n",
    "\n",
    "        # ❗ if nothing to keep → no folders created\n",
    "        if len(kept_pairs) == 0:\n",
    "            continue\n",
    "\n",
    "        # create folders ONLY now\n",
    "        img_dst_dir = os.path.join(dst_img_root, patient)\n",
    "        mask_dst_dir = os.path.join(dst_mask_root, patient)\n",
    "        os.makedirs(img_dst_dir, exist_ok=True)\n",
    "        os.makedirs(mask_dst_dir, exist_ok=True)\n",
    "\n",
    "        for img_f, mask_f in kept_pairs:\n",
    "            shutil.copy2(\n",
    "                os.path.join(img_src_dir, img_f),\n",
    "                os.path.join(img_dst_dir, img_f)\n",
    "            )\n",
    "            shutil.copy2(\n",
    "                os.path.join(mask_src_dir, mask_f),\n",
    "                os.path.join(mask_dst_dir, mask_f)\n",
    "            )\n",
    "\n",
    "        print(f\"Patient {patient}: kept {len(kept_pairs)} slices\")\n",
    "\n",
    "print(\"\\n✅ Images AND masks filtered correctly (no empty folders).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
